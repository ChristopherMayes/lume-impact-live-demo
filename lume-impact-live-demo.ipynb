{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Live cu-inj-live-impact "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup directories, and convert dashboard notebook to a script for importing\n",
    "#!./setup.bash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from impact import evaluate_impact_with_distgen, run_impact_with_distgen\n",
    "from impact.tools import isotime\n",
    "from impact.evaluate import  default_impact_merit\n",
    "from impact import Impact\n",
    "\n",
    "from make_dashboard import make_dashboard\n",
    "from get_vcc_image import get_live_distgen_xy_dist, VCC_DEVICE_PV\n",
    "\n",
    "from lcls_live.tools import NpEncoder\n",
    "\n",
    "import matplotlib as mpl\n",
    "\n",
    "from pmd_beamphysics.units import e_charge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import h5py\n",
    "import json\n",
    "import epics\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import toml\n",
    "from time import sleep, time\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import matplotlib as mpl\n",
    "mpl.use('Agg')\n",
    "\n",
    "# Nicer plotting\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Top level config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEBUG=False\n",
    "USE_VCC = True\n",
    "LIVE = True\n",
    "SNAPSHOT = 'examples/sc_inj-snapshot-2022-11-12T12:38:08-08:00.h5'\n",
    "MIN_CHARGE_pC = 10\n",
    "\n",
    "MODEL = 'sc_inj'\n",
    "\n",
    "config = toml.load(\"configs/sdf_sc_inj.toml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PREFIX = f'lume-impact-live-demo-{MODEL}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "# Gets or creates a logger\n",
    "logger = logging.getLogger(PREFIX)  \n",
    "\n",
    "# set log level\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "# define file handler and set formatter\n",
    "file_handler = logging.FileHandler(f'{PREFIX}.log')\n",
    "#formatter    = logging.Formatter('%(asctime)s : %(levelname)s : %(name)s : %(message)s')\n",
    "formatter    = logging.Formatter(fmt=\"%(asctime)s :  %(name)s : %(message)s \", datefmt=\"%Y-%m-%dT%H:%M:%S%z\")\n",
    "\n",
    "# Add print to stdout\n",
    "logger.addHandler(logging.StreamHandler(sys.stdout))\n",
    "\n",
    "file_handler.setFormatter(formatter)\n",
    "\n",
    "# add file handler to logger\n",
    "logger.addHandler(file_handler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving and loading\n",
    "def save_pvdata(filename, pvdata, isotime):\n",
    "    with h5py.File(filename, 'w') as h5:\n",
    "        h5.attrs['isotime'] = np.string_(isotime)\n",
    "        for k, v in pvdata.items():\n",
    "            if isinstance(v, str):\n",
    "                v =  np.string_(v)\n",
    "            h5[k] = v \n",
    "def load_pvdata(filename):\n",
    "    \n",
    "    if not os.path.exists(filename):\n",
    "        raise ValueError(f'H5 file does not exist: {filename} ')\n",
    "    pvdata = {}\n",
    "    with h5py.File(filename, 'r') as h5:\n",
    "        isotime = h5.attrs['isotime']\n",
    "        for k in h5:\n",
    "            v = np.array(h5[k])        \n",
    "            if v.dtype.char == 'S':\n",
    "                v = str(v.astype(str))\n",
    "            pvdata[k] = v\n",
    "            \n",
    "    return pvdata, isotime\n",
    "# save_pvdata('test.h5', PVDATA, isotime()) \n",
    "# load_pvdata('test.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuration\n",
    "\n",
    "Set up basic input sources and output path, loaded from toml environment file.\n",
    "\n",
    "See README for required toml definition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HOST = config.get('host') # mcc-simul or 'sdf'\n",
    "if not HOST:\n",
    "    raise ValueError(\"host not defined in toml.\")\n",
    "    \n",
    "def get_path(key):\n",
    "    val = config.get(key)\n",
    "    if not val:\n",
    "        raise ValueError(f\"{key} not defined in toml.\")\n",
    "    val=os.path.expandvars(val)\n",
    "    if not os.path.exists(val):\n",
    "        raise ValueError(f\"{val} does not exist\")\n",
    "    return os.path.abspath(val)\n",
    "\n",
    "\n",
    "# Output dirs\n",
    "\n",
    "SUMMARY_OUTPUT_DIR = get_path('summary_output_dir')\n",
    "\n",
    "\n",
    "\n",
    "ARCHIVE_DIR = get_path('archive_dir')\n",
    "\n",
    "SNAPSHOT_DIR = get_path('snapshot_dir')\n",
    "\n",
    "\n",
    "# Dummy file for distgen\n",
    "DISTGEN_LASER_FILE = config.get('distgen_laser_file')\n",
    "if not DISTGEN_LASER_FILE:\n",
    "    raise ValueError(\"distgen_laser_file not defined in toml.\")\n",
    "\n",
    "# Number of processors\n",
    "NUM_PROCS = config.get('num_procs')\n",
    "if not NUM_PROCS:\n",
    "    raise ValueError(\"num_procs not defined in toml.\")\n",
    "else:\n",
    "    NUM_PROCS = int(NUM_PROCS)\n",
    "\n",
    "\n",
    "# if using sdf:\n",
    "if HOST == 'sdf':    \n",
    "    # check that environment variables are configured for execution\n",
    "    IMPACT_COMMAND = config.get(\"impact_command\")\n",
    "    if not IMPACT_COMMAND:\n",
    "        raise ValueError(\"impact_command not defined in toml.\")\n",
    "\n",
    "\n",
    "    IMPACT_COMMAND_MPI = config.get(\"impact_command_mpi\")\n",
    "    if not IMPACT_COMMAND_MPI:\n",
    "        raise ValueError(\"impact_command_mpi not defined in toml.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG0 = {}\n",
    "\n",
    "# Base settings\n",
    "SETTINGS0 = {\n",
    " 'distgen:n_particle': 10_000,   \n",
    " 'timeout': 10000,\n",
    " 'header:Nx': 32,\n",
    " 'header:Ny': 32,\n",
    " 'header:Nz': 32,\n",
    " 'numprocs': NUM_PROCS,\n",
    "# 'mpi_run': MPI_RUN_CMD\n",
    "   }\n",
    "\n",
    "SETTINGS0['numprocs'] = NUM_PROCS\n",
    "CONFIG0[\"workdir\"] = get_path('workdir')\n",
    "\n",
    "if DEBUG:\n",
    "    logger.info('DEBUG MODE: Running without space charge for speed. ')\n",
    "    SETTINGS0['distgen:n_particle'] = 1000\n",
    "    SETTINGS0['total_charge'] = 0\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "# Host config    \n",
    "if HOST in ('sdf', ):\n",
    "    \n",
    "     # SDF setup \n",
    "    SETTINGS0['command'] =  IMPACT_COMMAND\n",
    "    SETTINGS0['command_mpi'] =  IMPACT_COMMAND_MPI\n",
    "    SETTINGS0['mpi_run'] = config.get(\"mpi_run_cmd\")\n",
    "    \n",
    "elif HOST == 'local':\n",
    "    logger.info('Running locally')\n",
    "    \n",
    "else:\n",
    "    raise ValueError(f'Unknown host: {HOST}')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select: LCLS or FACET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PV -> Sim conversion table\n",
    "CSV =  f'pv_mapping/{MODEL}_impact.csv'  \n",
    "\n",
    "\n",
    "CONFIG0['impact_config']      =  get_path('config_file')\n",
    "CONFIG0['distgen_input_file'] =  get_path('distgen_input_file')\n",
    "\n",
    "PLOT_OUTPUT_DIR = get_path('plot_output_dir')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if MODEL == 'cu_inj':\n",
    "    VCC_DEVICE = 'CAMR:IN20:186' # LCLS   \n",
    "    \n",
    "    DASHBOARD_KWARGS = {'outpath':PLOT_OUTPUT_DIR,\n",
    "                    'screen1': 'YAG02',\n",
    "                    'screen2': 'YAG03',\n",
    "                    'screen3': 'OTR2',\n",
    "                    'ylim' : (0, None), # Emittance scale   \n",
    "                    'ylim2': (0, None), # sigma_x scale\n",
    "                    'name' : PREFIX\n",
    "                   }    \n",
    "    \n",
    "    SETTINGS0['stop'] = 16.5\n",
    "    SETTINGS0['distgen:t_dist:length:value'] =  4 * 1.65   #  Inferred pulse stacker FWHM: 4 ps, converted to tukey length\n",
    "    \n",
    "if MODEL == 'sc_inj':\n",
    "    VCC_DEVICE = 'CAMR:LGUN:950' # LCLS-II \n",
    "    \n",
    "    DASHBOARD_KWARGS = {'outpath':PLOT_OUTPUT_DIR,\n",
    "                    'screen1': 'YAG01B',\n",
    "                  #  'screen2': 'BEAM0',\n",
    "                  #  'screen3': 'OTR0H04',\n",
    "                    'screen2': 'CM01BEG',\n",
    "                    'screen3': 'BEAM0',\n",
    "                    'ylim' : (0, 3e-6), # Emittance scale   \n",
    "                    'ylim2': (0, None), # sigma_x scale                    \n",
    "                    'name' : PREFIX\n",
    "                   }    \n",
    "    \n",
    "    SETTINGS0['stop'] = 14 # 28\n",
    "    SETTINGS0['distgen:t_dist:sigma_t:value'] =  16 / 2.355   # ps, equivalent to 16ps FWHM from Feng\n",
    "    \n",
    "elif MODEL == 'f2e_inj':\n",
    "    VCC_DEVICE = 'CAMR:LT10:900' # FACET-II\n",
    "    \n",
    "    DASHBOARD_KWARGS = {'outpath':PLOT_OUTPUT_DIR,\n",
    "                    'screen1': 'PR10241',\n",
    "                    'screen2': 'PR10465',\n",
    "                    'screen3': 'PR10571',\n",
    "                    'ylim' : (0, 20e-6), # Emittance scale\n",
    "                    'name' : PREFIX\n",
    "                   }        \n",
    "    \n",
    "    SETTINGS0['distgen:t_dist:length:value'] =  3.65 * 1.65   #  Measured FWHM: 3.65 ps, converted to tukey length\n",
    "     \n",
    "else:\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG0, SETTINGS0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up monitors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gun: 700 kV\n",
    "# Buncher: 200 keV energy gain\n",
    "# Buncher: +60 deg relative to on-crest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF = pd.read_csv(CSV)#.dropna()\n",
    "\n",
    "PVLIST = list(DF['device_pv_name'].dropna()) \n",
    "if USE_VCC:\n",
    "    PVLIST = PVLIST + list(VCC_DEVICE_PV[VCC_DEVICE].values())\n",
    "\n",
    "#DF.set_index('device_pv_name', inplace=True)\n",
    "DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if LIVE:\n",
    "    MONITOR = {pvname:epics.PV(pvname) for pvname in PVLIST}\n",
    "    SNAPSHOT = None\n",
    "    sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_snapshot(snapshot_file=None):\n",
    "        \n",
    "    if LIVE:\n",
    "        itime = isotime()\n",
    "        pvdata =  {k:MONITOR[k].get() for k in MONITOR}\n",
    "    else:\n",
    "        print(snapshot_file)\n",
    "        pvdata, itime = load_pvdata(snapshot_file)\n",
    "        itime = itime.decode('utf-8')\n",
    "    \n",
    "    logger.info(f'Acquired settings from EPICS at: {itime}')\n",
    "    \n",
    "    for k, v in pvdata.items():\n",
    "        \n",
    "        if v is None:\n",
    "            raise ValueError(f'EPICS get for {k} returned None')\n",
    "        \n",
    "        if ':IMAGE:ARRAYDATA' in k.upper():\n",
    "            found = False\n",
    "            logger.info(f'Waiting for good {k}')\n",
    "            while not found:\n",
    "                if v is None:\n",
    "                    continue\n",
    "                if v.std() > 10:\n",
    "                    found = True\n",
    "                else:\n",
    "                    v = MONITOR[k].get()\n",
    "            if v.ptp() < 128:\n",
    "                v = v.astype(np.int8) # Downcast preemptively \n",
    "                                \n",
    "            pvdata[k] = v\n",
    "    return pvdata, itime\n",
    "# PVDATA, ITIME = get_snapshot(SNAPSHOT)\n",
    "# PVDATA, ITIME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#while True:\n",
    "#    get_pvdata()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EPICS -> Simulation settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_settings(csv, base_settings={}, snapshot_dir=None, snapshot_file=None):\n",
    "    \"\"\"\n",
    "    Fetches live settings for all devices in the CSV table, and translates them to simulation inputs\n",
    "     \n",
    "    \"\"\"\n",
    "    df = DF[DF['device_pv_name'].notna()]\n",
    "    assert len(df) > 0, 'Empty dataframe!'\n",
    "    \n",
    "    pv_names = list(df['device_pv_name'])\n",
    "\n",
    "    pvdata, itime = get_snapshot(snapshot_file)\n",
    "    \n",
    "    df['pv_value'] = [pvdata[k] for k in pv_names]\n",
    "    \n",
    "    # Assign impact\n",
    "    df['impact_value'] = df['impact_factor']*df['pv_value'] \n",
    "    if 'impact_offset' in df:\n",
    "        df['impact_value'] = df['impact_value']  + df['impact_offset']\n",
    "\n",
    "    # Collect settings\n",
    "    settings = base_settings.copy()\n",
    "    settings.update(dict(zip(df['impact_name'], df['impact_value'])))\n",
    "    \n",
    "    if DEBUG:\n",
    "        settings['total_charge'] = 0\n",
    "    else:\n",
    "        settings['total_charge'] = 1 # Will be updated with particles\n",
    "\n",
    "    # VCC image\n",
    "    if USE_VCC:\n",
    "        dfile, img, cutimg = get_live_distgen_xy_dist(filename=DISTGEN_LASER_FILE, vcc_device=VCC_DEVICE, pvdata=pvdata)  \n",
    "        settings['distgen:xy_dist:file'] = dfile\n",
    "    else:\n",
    "        img, cutimg = None, None\n",
    "        #settings['distgen:r_dist:max_r:value'] = 0.35 # TEMP     \n",
    "        \n",
    "    if snapshot_dir and not snapshot_file:\n",
    "        filename = os.path.abspath(os.path.join(snapshot_dir, f'{MODEL}-snapshot-{itime}.h5'))\n",
    "        total_charge_pC = settings['distgen:total_charge:value']\n",
    "        if total_charge_pC < MIN_CHARGE_pC:\n",
    "            logger.info(f'total charge is too low: {total_charge_pC:.2f} pC, not saving snapshot')         \n",
    "        else:\n",
    "            save_pvdata(filename, pvdata, itime)\n",
    "            logger.info(f'EPICS shapshot written: {filename}')\n",
    "        \n",
    "        \n",
    "    return settings, df, img, cutimg, itime\n",
    "\n",
    "#res = get_settings(CSV, SETTINGS0, snapshot_dir='.')\n",
    "# res[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get_settings(CSV, SETTINGS0, snapshot_dir='.', snapshot_file=SNAPSHOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gfile = CONFIG0['distgen_input_file']\n",
    "# from distgen import Generator\n",
    "# #fout = res[0]\n",
    "# G = Generator(gfile)\n",
    "# #G['xy_dist:file'] =  DISTGEN_LASER_FILE #'distgen_laser.txt'\n",
    "# if USE_VCC:\n",
    "#     G['xy_dist:file'] = res[0]['distgen:xy_dist:file'] \n",
    "# G['n_particle'] = 100000\n",
    "# G.run()\n",
    "# G.particles.plot('x', 'y', figsize=(5,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DO_TIMING = False\n",
    "\n",
    "if DO_TIMING:\n",
    "    import numpy as np\n",
    "    import time\n",
    "    results = []\n",
    "    tlist = []\n",
    "    nlist = 2**np.arange(1,8, 1)[::-1]\n",
    "    for n in nlist:\n",
    "        t1 = time.time()\n",
    "        LIVE_SETTINGS['numprocs'] = n\n",
    "        print(f'running wit {n}')\n",
    "        result = run_impact_with_distgen(LIVE_SETTINGS, **CONFIG0, verbose=False )\n",
    "        results.append(result)\n",
    "        dt = time.time() - t1\n",
    "        tlist.append(dt)\n",
    "        print(n, dt)     \n",
    "        \n",
    "    tlist, nlist        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get live values, run Impact-T, make dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Patch this into the function below for the dashboard creation\n",
    "def my_merit(impact_object, itime):\n",
    "    # Collect standard output statistics\n",
    "    merit0 = default_impact_merit(impact_object)\n",
    "    # Make the dashboard from the evaluated object\n",
    "    plot_file = make_dashboard(impact_object, itime=itime, **DASHBOARD_KWARGS)\n",
    "    #print('Dashboard written:', plot_file)\n",
    "    logger.info(f'Dashboard written: {plot_file}')\n",
    "    \n",
    "    # Make all readable\n",
    "    os.chmod(plot_file, 0o644)\n",
    "    \n",
    "    # Assign extra info\n",
    "    merit0['plot_file'] = plot_file    \n",
    "    merit0['isotime'] = itime\n",
    "    \n",
    "    # Clear any buffers\n",
    "    plt.close('all')\n",
    "\n",
    "    return merit0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run1():\n",
    "    dat = {}\n",
    "    \n",
    "    # Acquire settings\n",
    "    mysettings, df, img, cutimg, itime = get_settings(CSV,\n",
    "                                                           SETTINGS0,\n",
    "                                                           snapshot_dir=SNAPSHOT_DIR,\n",
    "                                                          snapshot_file=SNAPSHOT)        \n",
    "    dat['isotime'] = itime\n",
    "    \n",
    "    # Record inputs\n",
    "    dat['inputs'] = mysettings\n",
    "    dat['config'] = CONFIG0\n",
    "    dat['pv_mapping_dataframe'] = df.to_dict()\n",
    "    \n",
    "    logger.info(f'Running evaluate_impact_with_distgen...')\n",
    "\n",
    "    t0 = time()\n",
    "    \n",
    "    total_charge_pC = mysettings['distgen:total_charge:value']\n",
    "    if total_charge_pC < MIN_CHARGE_pC:\n",
    "        logger.info(f'total charge is too low: {total_charge_pC:.2f} pC, skipping')\n",
    "        return dat\n",
    "    \n",
    "    outputs = evaluate_impact_with_distgen(mysettings,\n",
    "                                       merit_f=lambda x: my_merit(x, itime),\n",
    "                                       archive_path=ARCHIVE_DIR,\n",
    "                                       **CONFIG0, verbose=True )\n",
    "    \n",
    "    dat['outputs'] =  outputs   \n",
    "    logger.info(f'...finished in {(time()-t0)/60:.1f} min')\n",
    "    fname = fname=f'{SUMMARY_OUTPUT_DIR}/{PREFIX}-{itime}.json'\n",
    "\n",
    "    json.dump(dat, open(fname, 'w'), cls=NpEncoder)\n",
    "    logger.info(f'Summary output written: {fname}')\n",
    "    return dat\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# result = run1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#result.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic config\n",
    "#result['config']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulation inputs\n",
    "#result['inputs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulation outputs\n",
    "# result['outputs']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show the plot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from IPython.display import Image\n",
    "# Image(filename=result['outputs']['plot_file'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# loop it\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    while True:\n",
    "        try:\n",
    "            run1()\n",
    "        except:\n",
    "            sleep(10)\n",
    "            logger.info('Something BAD happened. Sleeping for 10 s ...')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
